# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2017, grid
# This file is distributed under the same license as the ReNom package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2017.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: ReNom 2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2017-08-09 14:52+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.4.0\n"

#: ../../rsts/renom.layers.function.rst:2
msgid "renom.layers.function"
msgstr ""

#: of renom.layers.function.batch_normalize.BatchNormalize:1
msgid ""
"Batch normalization function [1]_. This layer accelerates learning speed "
"with reducing internal covariate shift and allow us to set high learning "
"rate."
msgstr "Batch normalization関数.この関数を使用すると高い学習率をセットしても学習が可能になる."

#: of renom.layers.function.batch_normalize.BatchNormalize:5
msgid ""
"When the forward propagation, if the argument ``inference`` is set to "
"False this layer calculates moving average of mean and variance. Other "
"wise the ``inference`` is set to True, this layer uses the moving average"
" for forward propagation."
msgstr ""
"順伝播時に引数 ``inference`` "
"にFalseがセットされていた場合,バッチごとの平均、分散を用いてバッチ正規化を行う.Trueがセットされていた場合、学習時に取られたバッチごとの統計量の移動平均を用いてバッチ正規化を行う."

#: of renom.layers.function.batch_normalize.BatchNormalize:10
msgid ""
"If the argument mode is set to 'feature', normalize prior-layer features "
"per patch."
msgstr "引数 mode に 'feature' がセットされた場合、バッチ正規化をチャネルごとに実行する."

#: of renom.layers.function.batch_normalize.BatchNormalize:12
#: renom.layers.function.dense.Dense:7
#, fuzzy
msgid "Input unit size."
msgstr "出力ユニットサイズ"

#: of renom.layers.function.batch_normalize.BatchNormalize:14
msgid "Momentum coefficient for the moving average."
msgstr "移動平均計算時に使用するモメンタム係数"

#: of renom.layers.function.batch_normalize.BatchNormalize:16
msgid "'activation'  or 'feature'"
msgstr "'activation' もしくは 'feature'をセット可能"

#: of renom.layers.function.batch_normalize.BatchNormalize:18
msgid "Small number added to avoid division by zero"
msgstr "Zero division エラーを避けるために用いる微小な定数"

#: of renom.layers.function.batch_normalize.BatchNormalize:23
#: renom.layers.function.conv2d.Conv2d:22
#: renom.layers.function.deconv2d.Deconv2d:22
#: renom.layers.function.dense.Dense:12
#: renom.layers.function.dropout.Dropout:12
#: renom.layers.function.dropout.SpatialDropout:12
#: renom.layers.function.flatten.Flatten:5 renom.layers.function.lrn.Lrn:23
#: renom.layers.function.lstm.Lstm:27
#: renom.layers.function.parameterized.Model.load:8
#: renom.layers.function.parameterized.Model.save:8
#: renom.layers.function.parameterized.Model.train:5
#: renom.layers.function.parameterized.Model.values:8
#: renom.layers.function.parameterized.Sequential:8
#: renom.layers.function.pool2d.AveragePool2d:13
#: renom.layers.function.pool2d.MaxPool2d:13
msgid "Example"
msgstr ""

#: of renom.layers.function.batch_normalize.BatchNormalize:35
msgid ""
"Sergey Ioffe, Christian Szegedy.(2015).Batch Normalization: Accelerating "
"Deep Network Training by Reducing Internal Covariate Shift"
msgstr ""

#: of renom.layers.function.conv2d.Conv2d:1
#: renom.layers.function.deconv2d.Deconv2d:1
msgid "2d convolution function."
msgstr "2D畳み込み関数."

#: of renom.layers.function.conv2d.Conv2d:3
#: renom.layers.function.deconv2d.Deconv2d:3
msgid ""
"This class creates a convolution filter to be convolved with the input "
"tensor. The instance of this class only accepts and outputs 4d tensors."
msgstr "このクラスは畳込フィルタを持ち、入力に対してフィルタとの畳込み演算を実行する.４次元テンソルデータのみを入力として受け付ける."

#: of renom.layers.function.conv2d.Conv2d:7
#: renom.layers.function.deconv2d.Deconv2d:7
msgid ""
"At instantiation, in the case of int input, filter, padding, and stride, "
"the shape will be symmetric."
msgstr "インスタンス化時に,フィルタサイズ、パディング、ストッライドなどのパラメータをintもしくはtupleで与えることができる."

#: of renom.layers.function.conv2d.Conv2d:9
#: renom.layers.function.deconv2d.Deconv2d:9
msgid "The dimensionality of the output."
msgstr "出力チャンネル数"

#: of renom.layers.function.conv2d.Conv2d:11
#: renom.layers.function.pool2d.AveragePool2d:4
#: renom.layers.function.pool2d.MaxPool2d:4
msgid "Filter size of the convolution kernel."
msgstr "フィルタサイズ"

#: of renom.layers.function.conv2d.Conv2d:13
#: renom.layers.function.pool2d.AveragePool2d:6
#: renom.layers.function.pool2d.MaxPool2d:6
msgid "Size of the zero-padding around the image."
msgstr "ゼロパディングサイズ"

#: of renom.layers.function.conv2d.Conv2d:15
#: renom.layers.function.pool2d.AveragePool2d:8
#: renom.layers.function.pool2d.MaxPool2d:8
msgid "Stride-size of the convolution."
msgstr "ストライドサイズ"

#: of renom.layers.function.conv2d.Conv2d:17
#: renom.layers.function.deconv2d.Deconv2d:17
msgid "Input unit size. This must be a tuple like (Channel, Height, Width)."
msgstr "入力データサイズ. (channel, height, width)形式のtupleに対応."

#: of renom.layers.function.conv2d.Conv2d:34
msgid "Tensor data format is **NCHW**."
msgstr "テンソルデータのフォーマットは **NCHW**　の並び順となっている."

#: of renom.layers.function.deconv2d.Deconv2d:11
msgid "Filter size to witch used as convolution kernel."
msgstr "フィルタサイズ"

#: of renom.layers.function.deconv2d.Deconv2d:13
msgid "Pad around image by 0 according to this size."
msgstr "ゼロパディングサイズ"

#: of renom.layers.function.deconv2d.Deconv2d:15
msgid "Specifying the strides of the convolution."
msgstr "ストライドサイズ"

#: of renom.layers.function.dense.Dense:1
msgid "Fully connected layer as described bellow."
msgstr "以下の式で表される全結合レイヤ"

#: of renom.layers.function.dense.Dense:3
msgid ":math:`f(x)= w \\cdot x + b`"
msgstr ""

#: of renom.layers.function.dense.Dense:5
msgid "Output unit size."
msgstr "出力ユニットサイズ"

#: of renom.layers.function.dropout.Dropout:1
msgid "Applies Dropout [2]_ to the input."
msgstr "入力に対してドロップアウト [2]_ を適用する."

#: of renom.layers.function.dropout.Dropout:3
msgid ""
"Dropout function randomly selects a fraction (specified by dropout_ratio)"
" of the data sets them to zero. Remaining data will be rescaled by ``1/(1"
" - dropout_ratio)``."
msgstr ""
"``dropout_ratio`` に与えられた割合で入力をランダムに0とする.0とならなかった値に対しては ``1/(1 - "
"dropout_ratio)`` をかけている."

#: of renom.layers.function.dropout.Dropout:7
#: renom.layers.function.dropout.SpatialDropout:4
msgid "Dropout ratio."
msgstr "ドロップアウト率"

#: of renom.layers.function.dropout.Dropout:34
msgid ""
"Hinton, Geoffrey E.; Srivastava, Nitish; Krizhevsky, Alex; Sutskever, "
"Ilya; Salakhutdinov, Ruslan R. (2012). Improving neural networks by "
"preventing co-adaptation of feature detectors"
msgstr ""

#: of renom.layers.function.dropout.SpatialDropout:1
msgid ""
"Applies spatial dropout to the input. This function drops feature maps "
"randomly."
msgstr "チャンネルごとにドロップアウトを適用する."

#: of renom.layers.function.dropout.SpatialDropout:8
msgid ""
":exc:`AssertionError` -- An assertion error will be raised if the input "
"tensor dimension is not 4."
msgstr ""

#: of renom.layers.function.dropout.SpatialDropout:37
msgid "SpatialDropout only accepts 4d tensor data."
msgstr "SpatialDropoutは４次元テンソルのみを入力とする."

#: of renom.layers.function.flatten.Flatten:1
msgid "This function flattens an input tensor. It does not affect the batch size."
msgstr "入力テンソルを二次元テンソルに変形する.第一軸はバッチサイズ、第二軸はデータ次元数となる."

#: of renom.layers.function.lrn.Lrn:1
msgid "Local response normalization function [3]_ ."
msgstr "局所正規化レイヤ."

#: of renom.layers.function.lrn.Lrn:6
msgid ""
":math:`x_{c,i,j}` represents the c th conv. filter’s output at the "
"position of (i, j) in the feature map. :math:`y_{c_{out},j,i}` represents"
" the output of local response normalization. :math:`N` is the number of "
"the feature maps. :math:`n` is the adjacent feature map number. The "
"default argument values are recommended."
msgstr ""
":math:`x_{c,i,j}` は第cチャンネルの(i, j)ピクセル値を表す.:math:`y_{c_{out},j,i}` "
"は局所正規化レイヤの出力を表す.:math:`N` は特徴マップ数. :math:`n` "
"正規化に使用される隣接する特徴マップ数.ハイパーパラメータにはデフォルト値を推奨している."

#: of renom.layers.function.lrn.Lrn:12
msgid "Number of images used to be normalized."
msgstr "正規化を行う際に使用される画像数"

#: of renom.layers.function.lrn.Lrn:14
msgid "Constant."
msgstr "定数"

#: of renom.layers.function.lrn.Lrn:16
msgid "Scale factor."
msgstr "係数"

#: of renom.layers.function.lrn.Lrn:18
msgid "Exponential factor."
msgstr "係数"

#: of renom.layers.function.lrn.Lrn:32
msgid ""
"Alex Krizhevsky Krizhevsky, , Ilya IlyaSutskever Sutskever, Geoff. "
"ImageNet Classification with Deep Convolutional Neural Networks"
msgstr ""

#: of renom.layers.function.lstm.Lstm:1
#, fuzzy
msgid ""
"Long short time memory[4]_ . Lstm object has 12 weights and 4 biases "
"parameters to learn."
msgstr "Peephole付きLstmレイヤ.このレイヤは12個の重みと4つのバイアスを学習パラメータとして持つ."

#: of renom.layers.function.lstm.Lstm:4
msgid ""
"Weights applied to the input of the input gate, forget gate and output "
"gate. :math:`W_{ij}, Wgi_{ij}, Wgf_{ij}, Wgo_{ij}`"
msgstr "前の層から入力されるデータに対してかけられる重み. :math:`W_{ij}, Wgi_{ij}, Wgf_{ij}, Wgo_{ij}`"

#: of renom.layers.function.lstm.Lstm:7
msgid ""
"Weights applied to the recuurent input of the input gate, forget gate and"
" output gate. :math:`R_{ij}, Rgi_{ij}, Rgf_{ij}, Rgo_{ij}`"
msgstr "一時刻前から入力されるデータに対してかけられる重み. :math:`R_{ij}, Rgi_{ij}, Rgf_{ij}, Rgo_{ij}`"

#: of renom.layers.function.lstm.Lstm:44
msgid "Learning Precise Timing with LSTM Recurrent Networks"
msgstr ""

#: of renom.layers.function.lstm.Lstm.truncate:1
msgid "Truncates temporal connection."
msgstr "時系列方向の計算グラフのつながりを切る."

#: of renom.layers.function.parameterized.Model:1
msgid "Abstract class of neural network model."
msgstr "ニューラルネットワークモデルに関する抽象クラス."

#: of renom.layers.function.parameterized.Model.train:1
msgid ""
"Context manager to control whether a computational graph will be created "
"or not."
msgstr "計算グラフを作成するためのコンテキストを管理するコンテキストマネジャー."

#: of renom.layers.function.parameterized.Model.values:1
msgid "Generates nested tuple of underlying models and params of models."
msgstr ""

#: of renom.layers.function.parameterized.Model.values:3
msgid ""
"Each model generates tuple of two dictionary. The first dictionary "
"contains child models, keyed by attribute name. The second dictionary "
"contains parameters of the model, keyed by attribute name."
msgstr ""

#: of renom.layers.function.parameterized.Model.save:1
msgid "Save model weights."
msgstr "モデルの重みパラメータを保存する."

#: of renom.layers.function.parameterized.Model.save:3
msgid "File name to save model."
msgstr "モデルを保存する際のパス."

#: of renom.layers.function.parameterized.Model.load:1
msgid "Load saved weights to model."
msgstr "保存した重みパラメータをモデルにロードする."

#: of renom.layers.function.parameterized.Model.load:3
msgid "File name of saved model."
msgstr "ロードするモデルのパス"

#: of renom.layers.function.parameterized.Sequential:1
msgid "Sequential model."
msgstr ""

#: of renom.layers.function.parameterized.Sequential:3
msgid "A list of layer objects."
msgstr "レイヤオブジェクトのリスト"

#: of renom.layers.function.pool2d.MaxPool2d:1
msgid ""
"Max pooling function. In the case of int input, filter, padding, and "
"stride, the shape will be symmetric."
msgstr "Max poolingクラス."

#: of renom.layers.function.pool2d.AveragePool2d:1
msgid ""
"Average pooling function. In the case of int input, filter, padding, and "
"stride, the shape will be symmetric."
msgstr "Average poolingクラス."

#~ msgid "``epsilon`` is the coefficient used at calculation of moving average."
#~ msgstr ""

#~ msgid "("
#~ msgstr ""

#~ msgid "# child models of self {"
#~ msgstr ""

#~ msgid "'layer1': ("
#~ msgstr ""

#~ msgid "{},     # child model of self.layer1 {       # params of layer1"
#~ msgstr ""

#~ msgid ""
#~ msgstr ""

#~ msgid "}"
#~ msgstr ""

#~ msgid "), 'layer2': ("
#~ msgstr ""

#~ msgid "{},     # child model of self.layer2 {       # params of layer2"
#~ msgstr ""

#~ msgid "},"
#~ msgstr ""

#~ msgid "# params of self {}"
#~ msgstr ""

#~ msgid ")"
#~ msgstr ""

#~ msgid ""
#~ "Weights applied to the state input "
#~ "of the input gate, forget gate and"
#~ " output gate. :math:`P_{ij}, Pgi_{ij}, "
#~ "Pgf_{ij}, Pgo_{ij}`"
#~ msgstr "内部状態に対してかけられる重み. :math:`P_{ij}, Pgi_{ij}, Pgf_{ij}, Pgo_{ij}`"

#~ msgid ""
#~ "Felix A. Gers, Nicol N. Schraudolph, "
#~ "J ̈urgen Schmidhuber. Learning Precise "
#~ "Timing with LSTM Recurrent Networks"
#~ msgstr ""

#~ msgid "Example:"
#~ msgstr ""

